# ğŸš€ é¡¹ç›®æ”¹è¿›è¡ŒåŠ¨è®¡åˆ’

åŸºäºå·¥ç¨‹åŒ–è¯„ä¼°ï¼Œæä¾›æŒ‰ä¼˜å…ˆçº§æ’åºçš„å…·ä½“æ”¹è¿›è®¡åˆ’ã€‚

## ğŸ”¥ P0 - ç´§æ€¥ä¿®å¤ (æœ¬å‘¨å†…å®Œæˆ)

### 1. æ·»åŠ å¥åº·æ£€æŸ¥ç«¯ç‚¹ âš ï¸ é«˜ä¼˜å…ˆçº§

#### é—®é¢˜

- ç”Ÿäº§ç¯å¢ƒç¼ºå°‘å¥åº·æ£€æŸ¥ç«¯ç‚¹
- Dockerå®¹å™¨æ— æ³•è¿›è¡Œå¥åº·ç›‘æ§
- è´Ÿè½½å‡è¡¡å™¨æ— æ³•æ£€æµ‹æœåŠ¡çŠ¶æ€

#### è§£å†³æ–¹æ¡ˆ

```python
# src/football_predict_system/main.py
from datetime import datetime
from .core.health import get_health_checker

@app.get("/health", tags=["monitoring"])
async def health_check():
    """ç³»ç»Ÿå¥åº·æ£€æŸ¥ç«¯ç‚¹"""
    health_checker = get_health_checker()
    components = await health_checker.check_all_components()
    overall_status = health_checker.get_overall_status(components)
    
    return {
        "status": overall_status.value,
        "timestamp": datetime.utcnow().isoformat(),
        "components": [
            {
                "name": comp.name,
                "status": comp.status.value,
                "message": getattr(comp, 'message', ''),
                "response_time": getattr(comp, 'response_time', 0)
            }
            for comp in components
        ],
        "version": app.version
    }

@app.get("/health/ready", tags=["monitoring"])
async def readiness_check():
    """å°±ç»ªæ€§æ£€æŸ¥ - K8s readiness probe"""
    try:
        # æ£€æŸ¥å…³é”®ä¾èµ–
        db_manager = get_database_manager()
        cache_manager = await get_cache_manager()
        
        db_healthy = await db_manager.health_check()
        cache_healthy = await cache_manager.ping()
        
        if db_healthy and cache_healthy:
            return {"status": "ready"}
        else:
            raise HTTPException(status_code=503, detail="Service not ready")
    except Exception as e:
        raise HTTPException(status_code=503, detail=f"Service not ready: {str(e)}")

@app.get("/health/live", tags=["monitoring"])
async def liveness_check():
    """å­˜æ´»æ€§æ£€æŸ¥ - K8s liveness probe"""
    return {"status": "alive", "timestamp": datetime.utcnow().isoformat()}
```

### 2. æ·»åŠ Prometheusç›‘æ§

```python
# requirements.txt æ·»åŠ 
prometheus-fastapi-instrumentator>=7.0.0

# src/football_predict_system/main.py
from prometheus_fastapi_instrumentator import Instrumentator

# åœ¨appåˆ›å»ºåæ·»åŠ 
instrumentator = Instrumentator(
    should_group_status_codes=False,
    should_ignore_untemplated=True,
    should_respect_env_var=True,
    should_instrument_requests_inprogress=True,
    excluded_handlers=["/health", "/metrics"],
    env_var_name="ENABLE_METRICS",
    inprogress_name="http_requests_inprogress",
    inprogress_labels=True,
)

instrumentator.instrument(app)

@app.on_event("startup")
async def startup():
    instrumentator.expose(app)
```

### 3. æ›´æ–°Dockerå¥åº·æ£€æŸ¥

```dockerfile
# Dockerfile
FROM python:3.11-slim

# ... å…¶ä»–é…ç½® ...

# æ·»åŠ å¥åº·æ£€æŸ¥
HEALTHCHECK --interval=30s --timeout=10s --start-period=5s --retries=3 \
  CMD curl -f http://localhost:8000/health/live || exit 1

# å®‰è£…curlç”¨äºå¥åº·æ£€æŸ¥
RUN apt-get update && apt-get install -y curl && rm -rf /var/lib/apt/lists/*
```

```yaml
# docker-compose.yml æ›´æ–°
services:
  app:
    build: .
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
```

## ğŸŸ¡ P1 - é‡è¦æ”¹è¿› (2å‘¨å†…å®Œæˆ)

### 1. æå‡æµ‹è¯•è¦†ç›–ç‡åˆ°50%+

#### å½“å‰çŠ¶æ€: 39% â†’ ç›®æ ‡: 50%+

```bash
# åˆ›å»ºæµ‹è¯•è¦†ç›–ç‡æå‡è®¡åˆ’
mkdir -p tests/unit/api/v1
mkdir -p tests/integration/database
mkdir -p tests/integration/cache

# é‡ç‚¹æµ‹è¯•æ¨¡å—
echo "Priority modules for testing:
1. src/football_predict_system/api/v1/models.py (31% â†’ 80%)
2. src/football_predict_system/api/v1/predictions.py (45% â†’ 80%)
3. src/football_predict_system/domain/services.py (29% â†’ 80%)
4. src/football_predict_system/core/cache.py (16% â†’ 70%)"
```

#### APIæ¨¡å—æµ‹è¯•ç¤ºä¾‹

```python
# tests/unit/api/v1/test_models_comprehensive.py
import pytest
from fastapi.testclient import TestClient
from unittest.mock import Mock, patch

from football_predict_system.main import app
from football_predict_system.api.v1.models import ModelListResponse

client = TestClient(app)

class TestModelsAPI:
    """æ¨¡å‹APIç»¼åˆæµ‹è¯•"""
    
    def test_get_models_success(self):
        """æµ‹è¯•è·å–æ¨¡å‹åˆ—è¡¨æˆåŠŸ"""
        with patch('football_predict_system.domain.services.model_service') as mock_service:
            mock_service.get_models.return_value = []
            
            response = client.get("/api/v1/models")
            assert response.status_code == 200
            
    def test_get_model_performance(self):
        """æµ‹è¯•è·å–æ¨¡å‹æ€§èƒ½æŒ‡æ ‡"""
        model_id = "test-model-id"
        with patch('football_predict_system.domain.services.model_service') as mock_service:
            mock_service.get_model_performance.return_value = {
                "accuracy": 0.85,
                "precision": 0.80,
                "recall": 0.90
            }
            
            response = client.get(f"/api/v1/models/{model_id}/performance")
            assert response.status_code == 200
            data = response.json()
            assert "performance_metrics" in data
```

### 2. é›†æˆæµ‹è¯•æ¡†æ¶

```python
# tests/integration/conftest.py
import pytest
import asyncio
from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker
import redis

@pytest.fixture(scope="session")
def event_loop():
    """åˆ›å»ºäº‹ä»¶å¾ªç¯"""
    policy = asyncio.get_event_loop_policy()
    loop = policy.new_event_loop()
    yield loop
    loop.close()

@pytest.fixture(scope="session")
def test_database():
    """åˆ›å»ºæµ‹è¯•æ•°æ®åº“"""
    engine = create_engine("sqlite:///:memory:")
    # åˆ›å»ºè¡¨ç»“æ„
    # Base.metadata.create_all(engine)
    yield engine
    engine.dispose()

@pytest.fixture(scope="session")
def test_redis():
    """åˆ›å»ºæµ‹è¯•Redisè¿æ¥"""
    r = redis.Redis(host='localhost', port=6379, db=15)  # ä½¿ç”¨æµ‹è¯•æ•°æ®åº“
    yield r
    r.flushdb()  # æ¸…ç†æµ‹è¯•æ•°æ®

# tests/integration/test_database_integration.py
@pytest.mark.integration
class TestDatabaseIntegration:
    """æ•°æ®åº“é›†æˆæµ‹è¯•"""
    
    async def test_database_connection(self, test_database):
        """æµ‹è¯•æ•°æ®åº“è¿æ¥"""
        from football_predict_system.core.database import get_database_manager
        
        db_manager = get_database_manager()
        result = await db_manager.health_check()
        assert result is True
        
    async def test_cache_integration(self, test_redis):
        """æµ‹è¯•ç¼“å­˜é›†æˆ"""
        from football_predict_system.core.cache import get_cache_manager
        
        cache_manager = await get_cache_manager()
        await cache_manager.set("test_key", "test_value")
        value = await cache_manager.get("test_key")
        assert value == "test_value"
```

### 3. æ€§èƒ½æµ‹è¯•åŸºçº¿

```python
# requirements-dev.txt æ·»åŠ 
locust>=2.0.0

# tests/performance/locustfile.py
from locust import HttpUser, task, between

class FootballPredictionUser(HttpUser):
    wait_time = between(1, 3)
    
    def on_start(self):
        """æµ‹è¯•å¼€å§‹æ—¶çš„åˆå§‹åŒ–"""
        # å¯ä»¥åœ¨è¿™é‡Œç™»å½•æˆ–è®¾ç½®token
        pass
    
    @task(3)
    def health_check(self):
        """å¥åº·æ£€æŸ¥ç«¯ç‚¹æ€§èƒ½æµ‹è¯•"""
        self.client.get("/health")
    
    @task(2)
    def get_predictions(self):
        """é¢„æµ‹æ¥å£æ€§èƒ½æµ‹è¯•"""
        self.client.get("/api/v1/predictions")
    
    @task(1)
    def get_models(self):
        """æ¨¡å‹æ¥å£æ€§èƒ½æµ‹è¯•"""
        self.client.get("/api/v1/models")

# è¿è¡Œæ€§èƒ½æµ‹è¯•
# locust -f tests/performance/locustfile.py --host=http://localhost:8000
```

## ğŸŸ¢ P2 - ä¸­æœŸæ”¹è¿› (1ä¸ªæœˆå†…å®Œæˆ)

### 1. CDæµç¨‹è‡ªåŠ¨åŒ–

```yaml
# .github/workflows/cd.yml
name: Continuous Deployment

on:
  push:
    tags: ['v*']
  workflow_dispatch:
    inputs:
      environment:
        description: 'Deployment environment'
        required: true
        default: 'staging'
        type: choice
        options:
        - staging
        - production

env:
  REGISTRY: ghcr.io
  IMAGE_NAME: ${{ github.repository }}

jobs:
  build:
    runs-on: ubuntu-latest
    outputs:
      image: ${{ steps.image.outputs.image }}
    steps:
      - name: Checkout
        uses: actions/checkout@v4
        
      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3
        
      - name: Log in to Container Registry
        uses: docker/login-action@v3
        with:
          registry: ${{ env.REGISTRY }}
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}
          
      - name: Extract metadata
        id: meta
        uses: docker/metadata-action@v5
        with:
          images: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}
          tags: |
            type=ref,event=branch
            type=ref,event=pr
            type=semver,pattern={{version}}
            type=semver,pattern={{major}}.{{minor}}
            
      - name: Build and push
        uses: docker/build-push-action@v5
        with:
          context: .
          push: true
          tags: ${{ steps.meta.outputs.tags }}
          labels: ${{ steps.meta.outputs.labels }}
          cache-from: type=gha
          cache-to: type=gha,mode=max
          
      - name: Output image
        id: image
        run: echo "image=${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:${{ steps.meta.outputs.version }}" >> $GITHUB_OUTPUT

  deploy-staging:
    if: github.event.inputs.environment == 'staging' || startsWith(github.ref, 'refs/tags/v')
    needs: build
    runs-on: ubuntu-latest
    environment: staging
    steps:
      - name: Deploy to staging
        run: |
          echo "Deploying ${{ needs.build.outputs.image }} to staging"
          # å®é™…éƒ¨ç½²é€»è¾‘
          
  deploy-production:
    if: github.event.inputs.environment == 'production' && startsWith(github.ref, 'refs/tags/v')
    needs: [build, deploy-staging]
    runs-on: ubuntu-latest
    environment: production
    steps:
      - name: Deploy to production
        run: |
          echo "Deploying ${{ needs.build.outputs.image }} to production"
          # å®é™…éƒ¨ç½²é€»è¾‘
```

### 2. å¤šç¯å¢ƒé…ç½®

```bash
# åˆ›å»ºç¯å¢ƒé…ç½®ç›®å½•
mkdir -p configs/{dev,staging,prod}

# configs/base.env
DATABASE_POOL_SIZE=10
REDIS_TIMEOUT=5
LOG_LEVEL=INFO

# configs/dev/app.env
DEBUG=true
LOG_LEVEL=DEBUG
DATABASE_URL=sqlite:///./dev.db

# configs/staging/app.env
DEBUG=false
DATABASE_URL=${STAGING_DATABASE_URL}
REDIS_URL=${STAGING_REDIS_URL}

# configs/prod/app.env
DEBUG=false
DATABASE_URL=${PROD_DATABASE_URL}
REDIS_URL=${PROD_REDIS_URL}
```

```python
# src/football_predict_system/core/config.py æ›´æ–°
import os
from pathlib import Path

class Settings(BaseSettings):
    # ... ç°æœ‰é…ç½® ...
    
    environment: str = "dev"
    
    class Config:
        env_file = [
            ".env",
            f"configs/base.env",
            f"configs/{os.getenv('APP_ENV', 'dev')}/app.env"
        ]
        env_file_encoding = 'utf-8'
```

## ğŸ”µ P3 - é•¿æœŸä¼˜åŒ– (2-3ä¸ªæœˆ)

### 1. APMé›†æˆ (é€‰æ‹©ä¸€ä¸ª)

#### é€‰é¡¹A: Datadog APM

```python
# requirements.txt
ddtrace>=2.0.0

# src/football_predict_system/main.py
from ddtrace import tracer
from ddtrace.contrib.fastapi import patch

# å¯ç”¨FastAPIè¿½è¸ª
patch()

# è‡ªå®šä¹‰è¿½è¸ª
@tracer.wrap("business_logic")
def process_prediction(data):
    # ä¸šåŠ¡é€»è¾‘
    pass
```

#### é€‰é¡¹B: OpenTelemetry (å¼€æº)

```python
# requirements.txt
opentelemetry-api>=1.20.0
opentelemetry-sdk>=1.20.0
opentelemetry-auto-instrumentation>=0.41b0

# å¯åŠ¨æ—¶è‡ªåŠ¨instrument
# opentelemetry-bootstrap --action=install
# opentelemetry-instrument python -m uvicorn main:app
```

### 2. æ—¥å¿—èšåˆ

```yaml
# docker-compose.observability.yml
version: '3.8'
services:
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.10.0
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
    ports:
      - "9200:9200"
      
  kibana:
    image: docker.elastic.co/kibana/kibana:8.10.0
    ports:
      - "5601:5601"
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
      
  logstash:
    image: docker.elastic.co/logstash/logstash:8.10.0
    ports:
      - "5044:5044"
    volumes:
      - ./logstash.conf:/usr/share/logstash/pipeline/logstash.conf
```

## ğŸ“Š å®æ–½æ—¶é—´è¡¨

| å‘¨æ•° | ä¸»è¦ä»»åŠ¡ | å®Œæˆæ ‡å‡† |
|------|----------|----------|
| **Week 1** | P0ä»»åŠ¡ | å¥åº·æ£€æŸ¥ç«¯ç‚¹ä¸Šçº¿ï¼Œç›‘æ§é›†æˆ |
| **Week 2-3** | P1æµ‹è¯•æå‡ | è¦†ç›–ç‡è¾¾åˆ°50%ï¼Œé›†æˆæµ‹è¯•è¿è¡Œ |
| **Week 4** | P1æ€§èƒ½åŸºçº¿ | æ€§èƒ½æµ‹è¯•æ¡†æ¶å»ºç«‹ï¼ŒåŸºçº¿ç¡®å®š |
| **Week 5-8** | P2éƒ¨ç½²æµç¨‹ | CDæµç¨‹ä¸Šçº¿ï¼Œå¤šç¯å¢ƒéƒ¨ç½² |
| **Week 9-12** | P3ç›‘æ§æ·±åŒ– | APMé›†æˆï¼Œæ—¥å¿—èšåˆç³»ç»Ÿ |

## ğŸ¯ æˆåŠŸæŒ‡æ ‡

### çŸ­æœŸæŒ‡æ ‡ (1ä¸ªæœˆ)

- âœ… å¥åº·æ£€æŸ¥ç«¯ç‚¹å“åº”æ—¶é—´ < 100ms
- âœ… æµ‹è¯•è¦†ç›–ç‡ > 50%
- âœ… CI/CDæµç¨‹è‡ªåŠ¨åŒ–ç‡ > 90%

### ä¸­æœŸæŒ‡æ ‡ (3ä¸ªæœˆ)  

- âœ… é›¶å®•æœºéƒ¨ç½²æˆåŠŸç‡ > 99%
- âœ… ç”Ÿäº§é—®é¢˜å¹³å‡æ¢å¤æ—¶é—´ < 5åˆ†é’Ÿ
- âœ… ä»£ç è´¨é‡è¯„åˆ† > 85åˆ†

### é•¿æœŸæŒ‡æ ‡ (6ä¸ªæœˆ)

- âœ… ç³»ç»Ÿå¯ç”¨æ€§ > 99.9%
- âœ… APIå“åº”æ—¶é—´P95 < 500ms
- âœ… æµ‹è¯•è¦†ç›–ç‡ > 80%

---

**ä¸‹ä¸€æ­¥è¡ŒåŠ¨**: ä»P0ä»»åŠ¡å¼€å§‹ï¼ŒæŒ‰ç…§ä¼˜å…ˆçº§é€æ­¥å®æ–½ã€‚å»ºè®®æ¯å‘¨reviewè¿›åº¦ï¼Œç¡®ä¿æŒ‰è®¡åˆ’æ¨è¿›ã€‚
