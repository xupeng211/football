---
name: CI
on:
  push:
    branches: [main, dev, feat/ci-foundation, feat/ci-tighten]
  pull_request:
    branches: [main, dev]

permissions:
  contents: read

env:
  PIP_DISABLE_PIP_VERSION_CHECK: 1
  PIP_DEFAULT_TIMEOUT: 60
  UV_SYSTEM_PYTHON: 1

jobs:
  test:
    runs-on: ubuntu-22.04
    defaults:
      run:
        shell: bash

    steps:
      - name: Checkout code
        uses: actions/checkout@v5
        with:
          fetch-depth: 0

      - name: Set up Python 3.11.9
        uses: actions/setup-python@v5
        with:
          python-version: "3.11.9"

      - name: Cache pip packages
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt', '**/uv.lock') }}
          restore-keys: |
            ${{ runner.os }}-pip-

      - name: Install system dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y --no-install-recommends build-essential

      - name: Install Python dependencies with uv priority
        run: |
          echo "::group::Dependency Installation"
          python -m pip install -U pip uv

          # Priority 1: Use uv.lock if available for exact CI reproducibility
          if [ -f "uv.lock" ]; then
            echo "🚀 Using uv.lock for exact dependency reproduction..."
            uv pip sync --frozen uv.lock || {
              echo "⚠️ uv.lock sync failed, falling back to requirements.txt"
              pip install -r requirements.txt
            }
          elif [ -f "requirements.txt" ]; then
            echo "📦 Using requirements.txt..."
            pip install -r requirements.txt
          else
            echo "❌ No dependency file found"
            exit 1
          fi

          # Install project in editable mode
          pip install -e .

          # Install additional dev tools
          pip install pre-commit ruff mypy pytest pytest-cov bandit diff-cover
          echo "::endgroup::"

      - name: Cache pre-commit
        uses: actions/cache@v4
        with:
          path: ~/.cache/pre-commit
          key: ${{ runner.os }}-pre-commit-${{ hashFiles('.pre-commit-config.yaml') }}

      - name: Validate Configs (syntax + single-source)
        run: |
          echo "::group::Config Validation"
          # Validate TOML syntax
          python -c "import tomllib; [tomllib.load(open(f,'rb')) for f in ['pyproject.toml', '.gitleaks.toml'] if __import__('os').path.exists(f)]"
          # Validate YAML syntax
          python -c "import yaml; [yaml.safe_load(open(f)) for f in ['.github/workflows/ci.yml'] if __import__('os').path.exists(f)]"
          echo "✅ Configuration syntax validation passed"
          echo "::endgroup::"

      - name: Run code formatting check
        run: |
          echo "::group::Code Formatting"
          ruff format --check .
          echo "::endgroup::"

      - name: Run linting
        run: |
          echo "::group::Linting"
          ruff check .
          echo "::endgroup::"

      - name: Run type checking (core modules - strict)
        continue-on-error: true
        run: |
          echo "::group::Type Checking - Core Modules"
          # Check core modules strictly
          for dir in apps data_pipeline trainer; do
            if [ -d "$dir" ]; then
            if [ -d "$dir" ]; then
              echo "🔍 Advisory type checking: $dir/"
              mypy "$dir/" --ignore-missing-imports --no-strict-optional || echo "⚠️ Type issues in $dir/ (advisory only)"
            fi
          echo "::endgroup::"

      - name: Run type checking (other modules - advisory)
        continue-on-error: true
        run: |
          echo "::group::Type Checking - Other Modules (Advisory)"
          echo "🔍 Advisory type checking for remaining modules..."
          for dir in tests scripts models infra docs; do
            if [ -d "$dir" ]; then
              echo "Advisory check: $dir/"
              mypy "$dir/" --ignore-missing-imports --no-strict-optional || echo "⚠️ Type issues in $dir/ (advisory only)"
            fi
          done
          echo "::endgroup::"

      - name: Run security scan
        run: |
          echo "::group::Security Scan"
          bandit -r . --configfile pyproject.toml
          echo "::endgroup::"

      - name: Run gitleaks (strict)
        uses: gitleaks/gitleaks-action@v2
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          GITLEAKS_CONFIG: .gitleaks.toml

      - name: Run tests with coverage gate (single run)
        env:
          COV_MIN: ${{ vars.COV_MIN || '15' }}
          TEST_SEED: 42
        run: |
          echo "::group::Tests with Coverage Gate"
          set -euo pipefail

          # Dynamic coverage directory detection
          COV_ARGS=""
          for d in apps data_pipeline models trainer; do
            [ -d "$d" ] && COV_ARGS="$COV_ARGS --cov=$d"
          done

          # Fallback to root if no specific directories found
          if [ -z "$COV_ARGS" ]; then
            echo "📁 No specific coverage directories found, using root"
            COV_ARGS="--cov=."
          else
            echo "📁 Coverage directories: $COV_ARGS"
          fi

          # Single comprehensive test run with all reports
          pytest -v ${COV_ARGS} \
            --cov-report=xml \
            --cov-report=term-missing \
            --cov-report=html \
            --cov-report=json \
            --cov-fail-under="${COV_MIN}" \
            tests/ || {
              echo "❌ Tests failed or coverage below threshold (${COV_MIN}%)"
              exit 1
            }

          echo "✅ Tests passed with coverage above ${COV_MIN}%"
          echo "::endgroup::"

      - name: Collect changed files
        id: changed
        if: ${{ github.event_name == 'pull_request' }}
        shell: bash
        run: |
          set -euo pipefail
          base_ref="${GITHUB_BASE_REF:-main}"
          git fetch origin "${base_ref}" --depth=1 || true
          files=$(git diff --name-only "origin/${base_ref}...HEAD" || true)
          # Convert multiline to single line with space separation
          files_single_line=$(echo "${files}" | tr '\n' ' ' | xargs)
          echo "files=${files_single_line}" >> "$GITHUB_OUTPUT"
          if echo "${files}" | grep -E '\.(py|pyi)$' > /dev/null; then
            echo "has_python_files=true" >> "$GITHUB_OUTPUT"
          else
            echo "has_python_files=false" >> "$GITHUB_OUTPUT"
          fi

      - name: Diff Coverage Gate (PR only)
        if: ${{ github.event_name == 'pull_request' && !contains(github.event.pull_request.labels.*.name, 'ci-bypass-coverage') && steps.changed.outputs.has_python_files == 'true' }}
        env:
          DIFF_COV_MIN: ${{ vars.DIFF_COV_MIN || 75 }}
        run: |
          set -euo pipefail
          base_ref="${{ github.base_ref || 'main' }}"
          git fetch origin "${base_ref}" --depth=1 || true
          # 生成报告（HTML/Markdown）
          diff-cover coverage.xml \
            --compare-branch "origin/${base_ref}" \
            --html-report diff-coverage.html \
            --markdown-report diff-coverage.md
          # 阈值校验（未达标非零退出）
          diff-cover coverage.xml \
            --compare-branch "origin/${base_ref}" \
            --fail-under ${DIFF_COV_MIN}

      - name: Upload coverage artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: ci-artifacts
          path: |
            .coverage
            coverage.xml
            coverage.json
            htmlcov/**
            pytestdebug.log
            diff-coverage.html
            diff-coverage.md
          if-no-files-found: ignore
          retention-days: 30
